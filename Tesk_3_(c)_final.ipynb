{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tesk 3-(c)-final.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOWm+fUOtWMPQbhn1w9Jkpd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prantik-pdeb/GSoC2022-QML/blob/main/Tesk_3_(c)_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3-(c) Implementing a QCNN model in TF Quantum"
      ],
      "metadata": {
        "id": "4_QFajivG9Yj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The electron-photon dataset (which can be found [here](https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2FML4SCI%2FML4SCI_GSoC%2Ftree%2Fmain%2FQMLHEP%2Fqcnn&sa=D&source=docs)) contains 100 samples for training and another 100 for testing, laid out as follows:\n",
        "\n",
        "a. data[\"x_train\"]: Training dataset of 100 32x32 images containing the particles' energy (100, 32, 32)\n",
        "\n",
        "b. data[\"y_train\"]:\" Training labels, 0 = \"photon\", 1 = \"electron\" (100,)\n",
        "\n",
        "c. data[\"x_test\"]: Test dataset of 100 32x32 images containing the particles' energy (100, 32, 32)\n",
        "\n",
        "d. data[\"y_test\"]:\" Test labels, 0 = \"photon\", 1 = \"electron\" (100,)"
      ],
      "metadata": {
        "id": "yNVL0b86HOUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download tensorflow quantum\n",
        "!pip install tensorflow-quantum"
      ],
      "metadata": {
        "id": "JCOKnVlYpm5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow and module dependecies \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import importlib, pkg_resources\n",
        "importlib.reload(pkg_resources)\n",
        "import tensorflow_quantum as tfq\n",
        "import cirq\n",
        "import sympy\n",
        "import operator\n",
        "\n",
        "#import visualozation tools\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit\n",
        "import matplotlib.image  as mpimg"
      ],
      "metadata": {
        "id": "2K0a_4AZpqqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''loading data electron-photon dataset containts 100 samples\n",
        "for training and 100 sampes for test'''\n",
        "'''['x_train'] and ['x_test'] training and test dataset of 100 32*32 images \n",
        "['y_train'] and ['y_test'] training and test level with 0 = photon, 1 = electron'''\n",
        "\n",
        "dataset = np.load('/content/electron-photon.npz')"
      ],
      "metadata": {
        "id": "zRof5P3BpseV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with dataset as data:\n",
        "  x_train = data['x_train']\n",
        "  y_train = data['y_train']\n",
        "  x_test = data['x_test']\n",
        "  y_test= data['y_test']"
      ],
      "metadata": {
        "id": "ubmufPHOpzPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "5HLHMCGpHjCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[1])\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "JOWjBOgSp0KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[1])\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "Av9KIDbkp7RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "metadata": {
        "id": "K8v2Nrh1qAwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "SHUFFLE_BUFFER_SIZE = 18\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "mgBrXUVCq37k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classical Convulational Neural Network "
      ],
      "metadata": {
        "id": "7mlPAtuXH6dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64,(3,3), activation= 'relu',\n",
        "                         input_shape=(32,32,1)),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(64,(3,3), activation= 'relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation= 'relu'),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')                                 \n",
        "])"
      ],
      "metadata": {
        "id": "Ro03huXHqCsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "-sGXbXsnInbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XxCUbizFqeoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_history = cnn_model.fit(train_dataset, epochs=100, validation_data = test_dataset)"
      ],
      "metadata": {
        "id": "cxzgQ5TkqkY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = cnn_model.evaluate(train_dataset)"
      ],
      "metadata": {
        "id": "hEG7vYXvqpsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = cnn_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "rsXA2mpIreuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result: Visualization of Classical Convolutional Neural Network"
      ],
      "metadata": {
        "id": "uAvhVTRbIJSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = cnn_history.history['accuracy']\n",
        "test_acc = cnn_history.history['val_accuracy']\n",
        "train_loss = cnn_history.history['loss']\n",
        "test_loss= cnn_history.history['val_loss']\n",
        "\n",
        "epochs=range(len(train_acc)) \n",
        "plt.plot(epochs, train_acc, 'r', label= \"Training Accuracy\")\n",
        "plt.plot(epochs, test_acc, 'b', label = \"Test Accuracy\")\n",
        "plt.title('Training and testing accuracy')\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, train_loss, 'r',label= \"Training Loss\")\n",
        "plt.plot(epochs, test_loss, 'b', label=\"Test Loss\")\n",
        "plt.title('Training and testing loss')\n",
        "plt.figure()"
      ],
      "metadata": {
        "id": "LE0PrYaCrkw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "# Implementation of Quantum Convolutional Neural Network (QCNN)\n"
      ],
      "metadata": {
        "id": "CNp0g0x8IVKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_img(img, dimension):\n",
        "    start = tuple(map(lambda a, da: a//2-da//2, img.shape, dimension))\n",
        "    end = tuple(map(operator.add, start, dimension))\n",
        "    slices = tuple(map(slice, start, end))\n",
        "    return img[slices]"
      ],
      "metadata": {
        "id": "vidd1OFS6RYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crop_size = (16, 16)\n",
        "x_train_cropped_size = np.array([crop_img(i, crop_size) for i in x_train])\n",
        "x_test_cropped_size = np.array([crop_img(i, crop_size) for i in x_test])"
      ],
      "metadata": {
        "id": "ec8mb8Gn9HMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of x_train dataset:',x_train_cropped_size.shape)\n",
        "print('Shape of x_test dataset:',x_test_cropped_size.shape)"
      ],
      "metadata": {
        "id": "pN4JwSy9AyV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train_cropped_size[1])\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "Dwf27jt2B4fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test_cropped_size[1])\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "qdA5k1WmCAJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add the color channel into the dataset (batch_size, height, width, channel)\n",
        "x_train_new_size = np.reshape(x_train_cropped_size, list(x_train_cropped_size.shape)+[1])\n",
        "x_test_new_size = np.reshape(x_test_cropped_size, list(x_test_cropped_size.shape)+[1])"
      ],
      "metadata": {
        "id": "n62OrL7h9HOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of x_train dataset:',x_train_new_size.shape)\n",
        "print('Shape of x_test dataset:',x_test_new_size.shape)"
      ],
      "metadata": {
        "id": "i4E9jToVAW6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#An image size of 32x32 is much too large for current quantum computers. Resize the image down to 4x4\n",
        "# Using the image resize function from tensorflow library for tf.image.resize\n",
        "x_train_small = np.array([tf.image.resize(img, (16,16)).numpy() for img in x_train_new_size])\n",
        "x_test_small = np.array([tf.image.resize(img, (16,16)).numpy() for img in x_test_new_size])\n",
        "x_train_small = np.reshape(x_train_small, x_train_small.shape[:3])\n",
        "x_test_small = np.reshape(x_test_small, x_test_small.shape[:3])\n",
        "#y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
        "#y_test = np.asarray(y_test).astype('float32').reshape((-1,1))\n",
        "y_train = y_train[:]\n",
        "y_test = y_test[:]"
      ],
      "metadata": {
        "id": "wlh7JOEK9HRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train_small[1])\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "4RUMp6vxCIPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test_small[1])\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "1fh-QkP6CLPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QConv(tf.keras.layers.Layer):\n",
        "    def __init__(self, filter_size, depth, activation=None, name=None, kernel_regularizer=None, **kwangs):\n",
        "        super(QConv, self).__init__(name=name, **kwangs)\n",
        "        self.filter_size = filter_size\n",
        "        self.depth = depth\n",
        "        self.learning_params = []\n",
        "        self.QCNN_layer_gen()\n",
        "        # self.circuit_tensor = tfq.convert_to_tensor([self.circuit])\n",
        "        self.activation = tf.keras.layers.Activation(activation)\n",
        "        self.kernel_regularizer = kernel_regularizer\n",
        "\n",
        "    def _next_qubit_set(self, original_size, next_size, qubits):\n",
        "        step = original_size // next_size\n",
        "        qubit_list = []\n",
        "        for i in range(0, original_size, step):\n",
        "            for j in range(0, original_size, step):\n",
        "                qubit_list.append(qubits[original_size*i + j])\n",
        "        return qubit_list\n",
        "\n",
        "    def _get_new_param(self):\n",
        "        \"\"\"\n",
        "        return new learnable parameter\n",
        "        all returned parameter saved in self.learning_params\n",
        "        \"\"\"\n",
        "        new_param = sympy.symbols(\"p\"+str(len(self.learning_params)))\n",
        "        self.learning_params.append(new_param)\n",
        "        return new_param\n",
        "    \n",
        "    def _QConv(self, step, target, qubits):\n",
        "        \"\"\"\n",
        "        apply learnable gates each quantum convolutional layer level\n",
        "        \"\"\"\n",
        "        yield cirq.CZPowGate(exponent=self._get_new_param())(qubits[target], qubits[target+step])\n",
        "        yield cirq.CXPowGate(exponent=self._get_new_param())(qubits[target], qubits[target+step])\n",
        "        \n",
        "    def QCNN_layer_gen(self):\n",
        "        \"\"\"\n",
        "        make quantum convolutional layer in QConv layer\n",
        "        \"\"\"\n",
        "        pixels = self.filter_size**2\n",
        "        # filter size: 2^n only for this version!\n",
        "        if np.log2(pixels) % 1 != 0:\n",
        "            raise NotImplementedError(\"filter size: 2^n only available\")\n",
        "        cirq_qubits = cirq.GridQubit.rect(self.filter_size, self.filter_size)\n",
        "        # mapping input data to circuit\n",
        "        input_circuit = cirq.Circuit()\n",
        "        input_params = [sympy.symbols('a%d' %i) for i in range(pixels)]\n",
        "        for i, qubit in enumerate(cirq_qubits):\n",
        "            input_circuit.append(cirq.rx(np.pi*input_params[i])(qubit))\n",
        "        # apply learnable gate set to QCNN circuit\n",
        "        QCNN_circuit = cirq.Circuit()\n",
        "        step_size = [2**i for i in range(np.log2(pixels).astype(np.int32))]\n",
        "        for step in step_size:\n",
        "            for target in range(0, pixels, 2*step):\n",
        "                QCNN_circuit.append(self._QConv(step, target, cirq_qubits))\n",
        "        # merge the circuits\n",
        "        full_circuit = cirq.Circuit()\n",
        "        full_circuit.append(input_circuit)\n",
        "        full_circuit.append(QCNN_circuit)\n",
        "        self.circuit = full_circuit # save circuit to the QCNN layer obj.\n",
        "        self.params = input_params + self.learning_params\n",
        "        self.op = cirq.Z(cirq_qubits[0])\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        self.width = input_shape[1]\n",
        "        self.height = input_shape[2]\n",
        "        self.channel = input_shape[3]\n",
        "        self.num_x = self.width - self.filter_size + 1\n",
        "        self.num_y = self.height - self.filter_size + 1\n",
        "        \n",
        "        self.kernel = self.add_weight(name=\"kenel\", \n",
        "                                      shape=[self.depth, \n",
        "                                             self.channel, \n",
        "                                             len(self.learning_params)],\n",
        "                                     initializer=tf.keras.initializers.glorot_normal(),\n",
        "                                     regularizer=self.kernel_regularizer)\n",
        "        self.circuit_tensor = tfq.convert_to_tensor([self.circuit] * self.num_x * self.num_y * self.channel)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # input shape: [N, width, height, channel]\n",
        "        # slide and collect data\n",
        "        stack_set = None\n",
        "        for i in range(self.num_x):\n",
        "            for j in range(self.num_y):\n",
        "                slice_part = tf.slice(inputs, [0, i, j, 0], [-1, self.filter_size, self.filter_size, -1])\n",
        "                slice_part = tf.reshape(slice_part, shape=[-1, 1, self.filter_size, self.filter_size, self.channel])\n",
        "                if stack_set == None:\n",
        "                    stack_set = slice_part\n",
        "                else:\n",
        "                    stack_set = tf.concat([stack_set, slice_part], 1)  \n",
        "        # -> shape: [N, num_x*num_y, filter_size, filter_size, channel]\n",
        "        stack_set = tf.transpose(stack_set, perm=[0, 1, 4, 2, 3])\n",
        "        # -> shape: [N, num_x*num_y, channel, filter_size, fiter_size]\n",
        "        stack_set = tf.reshape(stack_set, shape=[-1, self.filter_size**2])\n",
        "        # -> shape: [N*num_x*num_y*channel, filter_size^2]\n",
        "        \n",
        "        # total input citcuits: N * num_x * num_y * channel\n",
        "        circuit_inputs = tf.tile([self.circuit_tensor], [tf.shape(inputs)[0], 1])\n",
        "        circuit_inputs = tf.reshape(circuit_inputs, shape=[-1])\n",
        "        tf.fill([tf.shape(inputs)[0]*self.num_x*self.num_y, 1], 1)\n",
        "        outputs = []\n",
        "        for i in range(self.depth):\n",
        "            controller = tf.tile(self.kernel[i], [tf.shape(inputs)[0]*self.num_x*self.num_y, 1])\n",
        "            outputs.append(self.single_depth_QCNN(stack_set, controller, circuit_inputs))\n",
        "            # shape: [N, num_x, num_y] \n",
        "            \n",
        "        output_tensor = tf.stack(outputs, axis=3)\n",
        "        output_tensor = tf.math.acos(tf.clip_by_value(output_tensor, -1+1e-5, 1-1e-5)) / np.pi\n",
        "        # output_tensor = tf.clip_by_value(tf.math.acos(output_tensor)/np.pi, -1, 1)\n",
        "        return self.activation(output_tensor)\n",
        "          \n",
        "    def single_depth_QCNN(self, input_data, controller, circuit_inputs):\n",
        "        \"\"\"\n",
        "        make QCNN for 1 channel only\n",
        "        \"\"\"\n",
        "        # input shape: [N*num_x*num_y*channel, filter_size^2]\n",
        "        # controller shape: [N*num_x*num_y*channel, len(learning_params)]\n",
        "        input_data = tf.concat([input_data, controller], 1)\n",
        "        # input_data shape: [N*num_x*num_y*channel, len(learning_params)]\n",
        "        QCNN_output = tfq.layers.Expectation()(circuit_inputs, \n",
        "                                               symbol_names=self.params,\n",
        "                                               symbol_values=input_data,\n",
        "                                               operators=self.op)\n",
        "        # QCNN_output shape: [N*num_x*num_y*channel]\n",
        "        QCNN_output = tf.reshape(QCNN_output, shape=[-1, self.num_x, self.num_y, self.channel])\n",
        "        return tf.math.reduce_sum(QCNN_output, 3)\n",
        "        "
      ],
      "metadata": {
        "id": "7idLH0Zt6R6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width = np.shape(x_train_small)[1]\n",
        "height = np.shape(x_train_small)[2]\n",
        "\n",
        "qcnn_model = tf.keras.models.Sequential()\n",
        "\n",
        "#model.add(layers.Conv2D(16, (2, 2), activation='relu'))\n",
        "qcnn_model.add(QConv(filter_size=2, depth=8, activation='relu', \n",
        "                     name='qconv1', input_shape=(width, height, 1)))\n",
        "\n",
        "qcnn_model.add(tf.keras.layers.Flatten())\n",
        "qcnn_model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "qcnn_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "G30GAB9p6SAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qcnn_model.summary()"
      ],
      "metadata": {
        "id": "6iJNWyzR6gSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVGCircuit(QConv(filter_size=2, depth=0, activation='relu').circuit)"
      ],
      "metadata": {
        "id": "1PAIFtEbCpS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pydot\n",
        "import graphviz\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(qcnn_model, to_file='model_shapes.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "UhTlEVpTCsHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qcnn_model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'binary_crossentropy', \n",
        "                   metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "MuDV9pljCuDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qcnn_history = qcnn_model.fit(x_train_small, y_train, validation_data=(x_test_small, y_test),\n",
        "                              epochs=50, steps_per_epoch=10,batch_size=5)"
      ],
      "metadata": {
        "id": "D4_MmtXbC6VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = qcnn_model.evaluate(x_test_small, y_test)"
      ],
      "metadata": {
        "id": "PrfRlTSbDGtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = qcnn_model.evaluate(x_train_small, y_train)"
      ],
      "metadata": {
        "id": "mvRDux5fDPbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result: Visualization of Quantum Convolutional Neural Network (QNN)"
      ],
      "metadata": {
        "id": "B5QxKH1QI0f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = qcnn_history.history['accuracy']\n",
        "test_acc = qcnn_history.history['val_accuracy']\n",
        "train_loss = qcnn_history.history['loss']\n",
        "test_loss = qcnn_history.history['val_loss']\n",
        "\n",
        "epochs=range(len(train_acc)) \n",
        "plt.plot(epochs, train_acc, 'r', label= \"Training Accuracy\")\n",
        "plt.plot(epochs, test_acc, 'b', label = \"Test Accuracy\")\n",
        "plt.title('Training and testing accuracy')\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, train_loss, 'r',label= \"Training Loss\")\n",
        "plt.plot(epochs, test_loss, 'b', label=\"Test Loss\")\n",
        "plt.title('Training and testing loss')\n",
        "plt.figure()"
      ],
      "metadata": {
        "id": "rq3t8gijDPgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnn_history.history['loss'][:25], label='Classical Convolutional Neural Network(CNN)')\n",
        "plt.plot(qcnn_history.history['loss'][:25], label='Quantum Convolutional Neural Network(QCNN)')\n",
        "plt.title('Quantum vs Hybrid CNN performance')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend()\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MmOPNjGsDPln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(cnn_loss, qcnn_loss):\n",
        "    fig = plt.figure()\n",
        "    plt.plot(np.arange(len(cnn_loss)) + 1, cnn_loss, \"rs-\", label=\"Classical Convolutional Neural Network(CNN)\")\n",
        "    plt.plot(np.arange(len(qcnn_loss)) + 1, qcnn_loss, \"b^-\", label=\"Quantum Convolutional Neural Network(QCNN)\")\n",
        "    #plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
        "    plt.axis([1, 50, 0, 1])\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Test set loss\")\n",
        "    plt.grid(True)\n",
        "    fig.savefig('loss.png', dpi=300)"
      ],
      "metadata": {
        "id": "RW7yg5fbD8iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(cnn_history.history['loss'], qcnn_history.history['val_loss'])"
      ],
      "metadata": {
        "id": "5na1fG96ZHBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References"
      ],
      "metadata": {
        "id": "6hv8RLS1JO9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. A. Abbas, D. Sutter, C. Zoufal, A. Lucchi, A. Figalli, and S. Woerner, “The power of Quantum Neural Networks,” Nature Computational Science, vol. 1, no. 6, pp. 403–409, 2021. \n",
        "2. D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning representations by back-propagating errors,” Nature, vol. 323, no. 6088, pp. 533–536, 1986. \n",
        "3. “Deep Learning Specialization,” DeepLearning.AI, 24-Dec-2021. [Online]. Available: https://www.deeplearning.ai/program/deep-learning-specialization/. [Accessed: 01-Apr-2022]. \n",
        "4. “Deep learning,” Deep Learning. [Online]. Available: https://www.deeplearningbook.org/. [Accessed: 01-Apr-2022]. \n",
        "5. E. Farhi and H. Neven, “Classification with quantum neural networks on near term processors,” arXiv.org, 30-Aug-2018. [Online]. Available: https://arxiv.org/abs/1802.06002. [Accessed: 01-Apr-2022]. \n",
        "6. I. Cong, S. Choi, and M. D. Lukin, “Quantum Convolutional Neural Networks,” Nature Physics, vol. 15, no. 12, pp. 1273–1278, 2019. \n",
        "7. I. Kerenidis, J. Landman, and A. Prakash, “Quantum algorithms for deep convolutional neural networks,” arXiv.org, 04-Nov-2019. [Online]. Available: https://arxiv.org/abs/1911.01117. [Accessed: 01-Apr-2022]. \n",
        "8. M. Broughton, G. Verdon, T. McCourt, A. J. Martinez, J. H. Yoo, S. V. Isakov, P. Massey, R. Halavati, M. Y. Niu, A. Zlokapa, E. Peters, O. Lockwood, A. Skolik, S. Jerbi, V. Dunjko, M. Leib, M. Streif, D. Von Dollen, H. Chen, S. Cao, R. Wiersema, H.-Y. Huang, J. R. McClean, R. Babbush, S. Boixo, D. Bacon, A. K. Ho, H. Neven, and M. Mohseni, “TensorFlow quantum: A software framework for Quantum Machine Learning,” arXiv.org, 26-Aug-2021. [Online]. Available: https://arxiv.org/abs/2003.02989. [Accessed: 01-Apr-2022].  \n",
        "9. “Quantum Convolutional Neural Network &nbsp;: &nbsp; tensorflow quantum,” TensorFlow. [Online]. Available: https://www.tensorflow.org/quantum/tutorials/qcnn. [Accessed: 01-Apr-2022]. \n",
        "10. S. Oh, J. Choi, and J. Kim, “A tutorial on quantum convolutional Neural Networks (QCNN),” arXiv.org, 20-Sep-2020. [Online]. Available: https://arxiv.org/abs/2009.09423. [Accessed: 01-Apr-2022]. \n",
        "11. “Tensorflow Quantum,” TensorFlow. [Online]. Available: https://www.tensorflow.org/quantum. [Accessed: 01-Apr-2022]. \n",
        "12. Y. LeCun and Y. Bengio, “Convolutional Networks for Images Speech and Time Series.” [Online]. Available: https://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf. [Accessed: 01-Apr-2022]. \n",
        "13. Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” Nature, vol. 521, no. 7553, pp. 436–444, 2015. "
      ],
      "metadata": {
        "id": "bHF7S4fDJTyI"
      }
    }
  ]
}